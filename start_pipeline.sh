#!/bin/bash
# PIPELINE CDC COMPLETO - APRESENTAÃ‡ÃƒO AUTOMATIZADA
# SequÃªncia: PostgreSQL â†’ Scripts â†’ DBT â†’ Dashboard
# Uso: ./start_pipeline.sh

set -e

# Verificar se estamos no diretÃ³rio correto
if [ ! -f "dbt_project/dbt_project.yml" ]; then
    echo "ERRO: Execute este script a partir do diretÃ³rio raiz do projeto"
    echo "DiretÃ³rio atual: $(pwd)"
    exit 1
fi

# Carregar variÃ¡veis
if [ -f "config/env.config" ]; then
    source config/load_env.sh
else
    echo "ERRO: Arquivo config/env.config nÃ£o encontrado"
    exit 1
fi

# Cores
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

log_info() { echo -e "${BLUE}INFO: $1${NC}"; }
log_success() { echo -e "${GREEN}OK: $1${NC}"; }
log_warning() { echo -e "${YELLOW}AVISO: $1${NC}"; }
log_error() { echo -e "${RED}ERRO: $1${NC}"; }
log_step() { echo -e "${PURPLE}PASSO $1${NC}"; }
log_highlight() { echo -e "${CYAN}DESTAQUE: $1${NC}"; }

clear
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "    ðŸš€ PIPELINE CDC COMPLETO - APRESENTAÃ‡ÃƒO AUTOMATIZADA    "
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ðŸ“‹ SEQUÃŠNCIA DE INICIALIZAÃ‡ÃƒO:"
echo "   1ï¸âƒ£  DependÃªncias Python"
echo "   2ï¸âƒ£  PostgreSQL (Source + Target)"
echo "   3ï¸âƒ£  DBT (TransformaÃ§Ãµes)"
echo "   4ï¸âƒ£  Dashboard interativo"
echo "   5ï¸âƒ£  InserÃ§Ã£o contÃ­nua de dados"
echo ""
echo "ðŸ” Credenciais: admin/admin (todos os serviÃ§os)"
echo "â±ï¸  Tempo estimado: 3-5 minutos"
echo "ðŸŒ URLs serÃ£o exibidas quando prontas"
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# ============================================================================
# PASSO 0: INSTALAÃ‡ÃƒO DE DEPENDÃŠNCIAS (PRIMEIRO DE TUDO)
# ============================================================================
log_step "0: INSTALANDO DEPENDÃŠNCIAS PYTHON"

log_info "Verificando e instalando dependÃªncias necessÃ¡rias..."
if python3 scripts/instalar_dependencias.py; then
    log_success "DependÃªncias instaladas com sucesso"
else
    log_error "Falha na instalaÃ§Ã£o de dependÃªncias"
    log_info "Tentando continuar mesmo assim..."
fi

log_info "Instalando dependÃªncias do requirements.txt..."
if [ -f "requirements.txt" ]; then
    if pip3 install -r requirements.txt --quiet --disable-pip-version-check; then
        log_success "Requirements.txt instalado com sucesso"
    else
        log_warning "Falha ao instalar requirements.txt, mas continuando..."
    fi
else
    log_warning "Arquivo requirements.txt nÃ£o encontrado"
fi

echo ""

# ============================================================================
# PASSO 1: INICIANDO AMBIENTE COMPLETO
# ============================================================================
log_step "1: INICIANDO AMBIENTE COMPLETO (PostgreSQL + MinIO + DBT)"

log_info "Parando todos os contÃªineres existentes..."
docker compose -f config/docker-compose.yml down --remove-orphans -v 2>/dev/null || true

log_info "Iniciando todos os serviÃ§os via Docker Compose..."
docker compose -f config/docker-compose.yml up -d --remove-orphans --build

MAX_RETRIES=24 # Total de 2 minutos (24 * 5s)
CURRENT_RETRY=0

# Verificar PostgreSQL
log_info "Aguardando PostgreSQL Source (dados originais)..."
until docker compose -f config/docker-compose.yml exec -T postgres_source pg_isready -U "${POSTGRES_SOURCE_USER:-admin}" -d "${POSTGRES_SOURCE_DB_NAME:-db_source}" -q || [ "$CURRENT_RETRY" -ge "$MAX_RETRIES" ]; do
    log_info "Tentativa $((CURRENT_RETRY+1))/$MAX_RETRIES... PostgreSQL Source nÃ£o estÃ¡ pronto ainda. Aguardando 5s..."
    sleep 5
    CURRENT_RETRY=$((CURRENT_RETRY+1))
done

if [ "$CURRENT_RETRY" -ge "$MAX_RETRIES" ]; then
    log_error "PostgreSQL Source falhou ao iniciar apÃ³s $MAX_RETRIES tentativas!"
    exit 1
else
    log_success "PostgreSQL Source: ${POSTGRES_SOURCE_USER:-admin}@localhost:${POSTGRES_SOURCE_PORT}"
fi

# Verificar MinIO
log_info "Aguardando MinIO (Data Lake)..."
CURRENT_RETRY=0
until curl -f http://localhost:9000/minio/health/live >/dev/null 2>&1 || [ "$CURRENT_RETRY" -ge "$MAX_RETRIES" ]; do
    log_info "Tentativa $((CURRENT_RETRY+1))/$MAX_RETRIES... MinIO nÃ£o estÃ¡ pronto ainda. Aguardando 5s..."
    sleep 5
    CURRENT_RETRY=$((CURRENT_RETRY+1))
done

if [ "$CURRENT_RETRY" -ge "$MAX_RETRIES" ]; then
    log_error "MinIO falhou ao iniciar apÃ³s $MAX_RETRIES tentativas!"
    exit 1
else
    log_success "MinIO: http://localhost:9000 (Console: http://localhost:9001)"
fi

# Verificar DBT Runner
log_info "Verificando DBT Runner..."
if docker compose -f config/docker-compose.yml exec -T dbt_runner echo "DBT Runner OK" >/dev/null 2>&1; then
    log_success "DBT Runner: Container ativo e pronto"
else
    log_warning "DBT Runner pode nÃ£o estar totalmente pronto, mas continuando..."
fi

log_info "Criando estrutura do banco Source (tabelas e CDC)..."
# O script criar_tabelas.py jÃ¡ usa localhost:5430, que Ã© o postgres_source
# O script 02_configure_cdc.sql Ã© executado pelo entrypoint do postgres_source
if python3 scripts/criar_tabelas.py; then
    log_success "Estrutura e dados iniciais criados no Source."
else
    log_error "Falha na criaÃ§Ã£o da estrutura do Source."
    exit 1
fi

log_success "PostgreSQL Source configurado e pronto para uso"

# ============================================================================
# PASSO 2: INSERÃ‡ÃƒO DE DADOS INICIAIS
# ============================================================================
log_step "2: VERIFICANDO DADOS INICIAIS"

# Verificar se os dados foram criados pelo script criar_tabelas.py
log_info "Verificando dados no banco source..."
clientes_count=$(docker compose -f config/docker-compose.yml exec -T postgres_source psql -U "${POSTGRES_SOURCE_USER:-admin}" -d "${POSTGRES_SOURCE_DB_NAME:-db_source}" -t -c "SELECT COUNT(*) FROM clientes;" 2>/dev/null | tr -d ' ' || echo "0")

if [ "$clientes_count" -gt 0 ]; then
    log_success "Dados no Source: $clientes_count clientes"
else
    log_warning "Nenhum dado de cliente encontrado. Execute o script de inserÃ§Ã£o de dados se necessÃ¡rio."
fi

# ============================================================================
# PASSO 3: DBT AUTOMATIZADO
# ============================================================================
log_step "3: CONFIGURAÃ‡ÃƒO AUTOMATIZADA DO DBT"

log_info "Instalando dependÃªncias do DBT..."
python3 scripts/instalar_dependencias.py > /dev/null 2>&1

log_highlight "INICIANDO AUTO-CONFIGURAÃ‡ÃƒO INTELIGENTE DO DBT"
log_info "Sistema detectarÃ¡ automaticamente o estado e configurarÃ¡ DBT"

# Executar auto-configurador inteligente
if python3 scripts/auto_configure_dbt.py; then
    log_success "DBT AUTO-CONFIGURADO COM SUCESSO!"
    DBT_AUTO_SUCCESS=true
    
    # Tentar executar DBT
    log_info "Executando pipeline DBT automaticamente..."
    if python3 scripts/executar_dbt.py run; then
        log_success "Pipeline DBT executado com sucesso!"
    else
        log_warning "DBT configurado, mas execuÃ§Ã£o falhou (normal se ainda nÃ£o hÃ¡ dados replicados)"
    fi
else
    log_warning "Falha na auto-configuraÃ§Ã£o do DBT"
    DBT_AUTO_SUCCESS=false
fi

# ============================================================================
# PASSO 6: DEMONSTRAÃ‡ÃƒO INTERATIVA
# ============================================================================
log_step "6: INICIANDO DEMONSTRAÃ‡ÃƒO INTERATIVA"

# FunÃ§Ã£o para abrir URL no navegador
abrir_no_navegador() {
    local url=$1
    log_info "Abrindo $url no navegador..."
    
    # Detectar OS e abrir navegador
    if [[ "$OSTYPE" == "darwin"* ]]; then
        # macOS
        open "$url" 2>/dev/null || true
    elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
        # Linux
        xdg-open "$url" 2>/dev/null || true
    else
        log_warning "Por favor, abra manualmente: $url"
    fi
}

# Airbyte removido do projeto

# ============================================================================
# PASSO 4: INICIANDO DASHBOARD INTERATIVO
# ============================================================================
log_step "4: INICIANDO DASHBOARD INTERATIVO"

log_info "Verificando se Streamlit estÃ¡ instalado..."
if ! command -v streamlit &> /dev/null; then
    log_info "Instalando Streamlit..."
    pip3 install streamlit --quiet --disable-pip-version-check
fi

log_info "Iniciando Dashboard de visualizaÃ§Ã£o..."
streamlit run scripts/dashboard.py \
    --server.port 8501 \
    --server.address localhost \
    --server.headless true \
    --browser.gatherUsageStats false \
    > /tmp/dashboard.log 2>&1 &
DASHBOARD_PID=$!

# Aguardar dashboard inicializar
sleep 8
if ps -p $DASHBOARD_PID > /dev/null; then
    log_success "Dashboard iniciado! PID: $DASHBOARD_PID"
    log_success "Dashboard disponÃ­vel em: http://localhost:8501"
    abrir_no_navegador "http://localhost:8501"
else
    log_error "Dashboard falhou ao iniciar. Verifique os logs em /tmp/dashboard.log"
    exit 1
fi

# ============================================================================
# PASSO 5: INICIANDO INSERÃ‡ÃƒO CONTÃNUA DE DADOS
# ============================================================================
log_step "5: INICIANDO INSERÃ‡ÃƒO CONTÃNUA DE DADOS"

log_info "Iniciando simulaÃ§Ã£o de dados para CDC..."
python3 scripts/insere_dados.py > /tmp/insere_dados.log 2>&1 &
INSERSOR_PID=$!

# Aguardar um pouco para verificar se o processo iniciou corretamente
sleep 3
if ps -p $INSERSOR_PID > /dev/null; then
    log_success "Simulador de dados iniciado! PID: $INSERSOR_PID"
    log_success "Dados sendo inseridos continuamente para demonstrar CDC"
    log_info "Logs disponÃ­veis em: /tmp/insere_dados.log"
else
    log_error "Simulador de dados falhou ao iniciar. Verifique o script scripts/insere_dados.py"
    exit 1
fi

# ============================================================================
# STATUS FINAL COMPLETO
# ============================================================================
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log_highlight "ðŸŽ‰ PIPELINE AUTOMATIZADO E DEMONSTRAÃ‡ÃƒO INICIADOS!"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

echo ""
log_highlight "ðŸ–¥ï¸  SERVIÃ‡OS WEB DISPONÃVEIS:"
echo "ðŸ“Š Dashboard Principal: http://localhost:8501"
echo "ðŸ—„ï¸  MinIO Console: http://localhost:9001 (admin: minioadmin/minioadmin)"
echo "ðŸ˜ PostgreSQL Source: localhost:${POSTGRES_SOURCE_PORT:-5430} (admin/admin)"

echo ""
log_highlight "ðŸ¤– PROCESSOS ATIVOS:"
echo "âœ… Dashboard Streamlit (PID: ${DASHBOARD_PID:-N/A})"
echo "âœ… Insersor de dados CDC (PID: ${INSERSOR_PID:-N/A})"
echo "âœ… PostgreSQL + MinIO + DBT Runner (Docker)"
echo "âœ… DBT auto-configurado e executado"

echo ""
log_highlight "ðŸŽ¯ AMBIENTE TOTALMENTE FUNCIONAL!"
echo "Todos os componentes configurados automaticamente"

echo ""
log_highlight "ðŸŽ¯ COMO USAR O AMBIENTE:"
echo "1. ðŸ“Š Acesse o Dashboard: http://localhost:8501"
echo "2. ðŸ”„ Dados sÃ£o inseridos automaticamente a cada 30 segundos"
echo "3. ðŸ” Observe as transformaÃ§Ãµes DBT em tempo real"
echo "4. ðŸ—„ï¸  Explore o MinIO Console: http://localhost:9001"
echo "5. ðŸ˜ Conecte ao PostgreSQL: localhost:5430 (admin/admin)"

echo ""
log_highlight "ðŸ“ COMANDOS ÃšTEIS:"
echo "ðŸ“‹ Ver logs do insersor: tail -f /tmp/insere_dados.log"
echo "ðŸ“‹ Ver logs do dashboard: tail -f /tmp/dashboard.log"
echo "ðŸ”„ Executar DBT manualmente: python3 scripts/executar_dbt.py run"
echo "ðŸ“Š Ver estrutura do pipeline: python3 scripts/visualizar_pipeline.py"
echo "ðŸ›‘ Parar insersor: kill $INSERSOR_PID"
echo "ðŸ›‘ Parar dashboard: kill $DASHBOARD_PID"
echo "ðŸ§¹ Limpar ambiente: docker compose -f config/docker-compose.yml down -v"

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log_info "ðŸš€ PIPELINE RODANDO COM DEMONSTRAÃ‡ÃƒO INTERATIVA!"
log_info "âŒ¨ï¸  Pressione Ctrl+C para finalizar tudo"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# FunÃ§Ã£o para limpar ao sair
cleanup() {
    echo ""
    log_info "Encerrando demonstraÃ§Ã£o..."
    
    # Parar processos
    if [ ! -z "$DASHBOARD_PID" ] && ps -p $DASHBOARD_PID > /dev/null; then
        kill $DASHBOARD_PID 2>/dev/null || true
        log_info "Dashboard parado"
    fi
    
    if [ ! -z "$INSERSOR_PID" ] && ps -p $INSERSOR_PID > /dev/null; then
        kill $INSERSOR_PID 2>/dev/null || true
        log_info "Insersor de dados parado"
    fi
    
    log_success "DemonstraÃ§Ã£o encerrada!"
    exit 0
}

# Registrar funÃ§Ã£o de limpeza
trap cleanup EXIT INT TERM

# Loop de monitoramento com auto-reconfiguraÃ§Ã£o
while true; do
    sleep 60
    
    # Status dos containers
    postgres_status=$(docker compose -f config/docker-compose.yml ps postgres_source --format "table" | grep -c "Up" || echo "0")
    minio_status=$(docker compose -f config/docker-compose.yml ps minio --format "table" | grep -c "Up" || echo "0")
    dbt_status=$(docker compose -f config/docker-compose.yml ps dbt_runner --format "table" | grep -c "Up" || echo "0")
    
    # Contar registros no banco
    source_clientes=$(docker compose -f config/docker-compose.yml exec -T postgres_source psql -U admin -d db_source -t -c "SELECT COUNT(*) FROM clientes;" 2>/dev/null | tr -d ' ' || echo "0")
    
    # Verificar se processos ainda estÃ£o rodando
    dashboard_status="âŒ OFF"
    insersor_status="âŒ OFF"
    
    if [ ! -z "$DASHBOARD_PID" ] && ps -p $DASHBOARD_PID > /dev/null; then
        dashboard_status="âœ… ON"
    fi
    
    if [ ! -z "$INSERSOR_PID" ] && ps -p $INSERSOR_PID > /dev/null; then
        insersor_status="âœ… ON"
    fi
    
    # Status consolidado
    containers_status="PostgreSQL:$postgres_status MinIO:$minio_status DBT:$dbt_status"
    
    # Exibir status atualizado
    echo "$(date '+%H:%M:%S') | ðŸ“Š Clientes: $source_clientes | ðŸ³ Containers: $containers_status | ðŸ“ˆ Dashboard: $dashboard_status | ðŸ”„ Insersor: $insersor_status"
    
    # Auto-reconfiguraÃ§Ã£o inteligente do DBT se necessÃ¡rio
    if [ "$source_clientes" -gt 0 ] && [ "$DBT_AUTO_SUCCESS" != true ]; then
        log_info "Dados detectados! Executando DBT automaticamente..."
        if python3 scripts/executar_dbt.py run > /dev/null 2>&1; then
            log_success "DBT executado com sucesso!"
            DBT_AUTO_SUCCESS=true
        fi
    fi
done