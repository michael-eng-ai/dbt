# Pipeline de Dados Completo com DBT

Este projeto implementa um pipeline de dados completo para demonst## ğŸ—ï¸ **Arquitetura Detalhada**

### **Ordem do Pipeline de Dados**
```
1. ğŸ“ Scripts Python inserem dados â†’ PostgreSQL Source
2. ğŸ”„ DBT executa transformaÃ§Ãµes â†’ Bronze â†’ Silver â†’ Gold  
3. ğŸ“Š Dashboard consome dados transformados â†’ VisualizaÃ§Ã£o em tempo real
4. ğŸ”„ Scheduler mantÃ©m pipeline atualizado â†’ ExecuÃ§Ã£o automÃ¡tica
```

### **Fluxo TecnolÃ³gico**
- **Docker**: Infraestrutura (PostgreSQL, MinIO, DBT Runner)
- **Python**: AutomaÃ§Ã£o (inserÃ§Ã£o, scheduler, dashboard)
- **DBT**: TransformaÃ§Ãµes de dados (SQL + Jinja2)
- **Streamlit**: Interface web interativa
- **Credenciais Padronizadas**: admin/admin para todos os serviÃ§os

### **Camadas de Dados (MedalhÃ£o)**
```
ğŸ¥‰ Bronze â†’ Dados brutos (cÃ³pia exata do source)
ğŸ¥ˆ Silver â†’ Dados limpos e padronizados  
ğŸ¥‡ Gold â†’ AgregaÃ§Ãµes e mÃ©tricas de negÃ³cio
```T para transformaÃ§Ãµes em camadas (Bronze, Silver, Gold), incluindo dashboard interativo e simulaÃ§Ã£o de dados em tempo real.

## ğŸ—ï¸ Arquitetura do Pipeline

```
[Scripts Python] â†’ [PostgreSQL Source] â†’ [DBT TransformaÃ§Ãµes] â†’ [Dashboard Streamlit]
      â†“                    â†“                        â†“                     â†“
[InserÃ§Ã£o ContÃ­nua]  [Dados Originais]    [Bronze/Silver/Gold]    [VisualizaÃ§Ã£o Tempo Real]
                            â†“
                      [MinIO Data Lake]
```

### Componentes:

- **PostgreSQL Source**: Banco transacional com dados simulados e CDC habilitado
- **Scripts Python**: AutomaÃ§Ã£o para inserÃ§Ã£o contÃ­nua e execuÃ§Ã£o do pipeline
- **DBT**: TransformaÃ§Ãµes de dados em camadas medalhÃ£o (Bronze â†’ Silver â†’ Gold)
- **MinIO**: Data Lake S3-compatible para armazenamento
- **Dashboard Streamlit**: Interface web para visualizaÃ§Ã£o de mÃ©tricas em tempo real
- **Scheduler DBT**: Script Python para execuÃ§Ã£o automÃ¡tica do pipeline

### Vantagens desta Abordagem:

- âœ… **Pipeline Completo**: Demonstra todo o ciclo de dados
- âœ… **TransformaÃ§Ãµes DBT**: Implementa padrÃ£o medalhÃ£o completo
- âœ… **Dashboard Interativo**: VisualizaÃ§Ã£o em tempo real das mÃ©tricas
- âœ… **InserÃ§Ã£o AutomÃ¡tica**: Simula ambiente de produÃ§Ã£o
- âœ… **Setup Automatizado**: InicializaÃ§Ã£o com um comando

## ğŸ” **Credenciais Padronizadas**

**Todos os serviÃ§os usam:**
```
UsuÃ¡rio: admin
Senha: admin
```

## ğŸš€ **InicializaÃ§Ã£o Completa (Recomendado)**

```bash
# 1. Clone e acesse o diretÃ³rio
git clone <repo-url>
cd dbt

# 2. Execute o pipeline completo (automatizado)
./start_pipeline.sh

# 3. Aguarde a inicializaÃ§Ã£o (3-5 minutos)
# O script irÃ¡ automaticamente:
# - Instalar dependÃªncias Python
# - Subir PostgreSQL Source + MinIO
# - Configurar e executar DBT (Bronze â†’ Silver â†’ Gold)
# - Iniciar dashboard interativo
# - ComeÃ§ar inserÃ§Ã£o contÃ­nua de dados

# 4. Acesse as interfaces
# Dashboard: http://localhost:8501 (aberto automaticamente)
# MinIO: http://localhost:9001 (minioadmin/minioadmin)
# PostgreSQL: localhost:5430 (admin/admin)
```

## ğŸ¯ **OpÃ§Ãµes de ExecuÃ§Ã£o**

### 1ï¸âƒ£ **Pipeline Completo (Recomendado)**
```bash
./start_pipeline.sh
```
**Executa**: Todo o ambiente + Dashboard automÃ¡tico + InserÃ§Ã£o contÃ­nua

### 2ï¸âƒ£ **Pipeline DBT Focado**
```bash
./scripts/start_dbt_pipeline.sh
```
**Executa**: Apenas infraestrutura + DBT (sem dashboard automÃ¡tico)

### 3ï¸âƒ£ **ExecuÃ§Ã£o Manual do DBT**
```bash
# ApÃ³s qualquer uma das opÃ§Ãµes acima:
cd dbt_project
dbt run --models tag:bronze    # Camada Bronze
dbt run --models tag:silver    # Camada Silver  
dbt run --models tag:gold      # Camada Gold
dbt run                        # Pipeline completo
```

### 4ï¸âƒ£ **Scheduler AutomÃ¡tico**
```bash
python scripts/scheduler_dbt.py --interval 300  # A cada 5 minutos
python scripts/scheduler_dbt.py --run-once      # Apenas uma vez
```

### 5ï¸âƒ£ **Dashboard Independente**
```bash
streamlit run scripts/dashboard.py
```

### 6ï¸âƒ£ **Limpeza Completa**
```bash
./clean_docker_environment.sh
```
**âš ï¸ CUIDADO:** Remove TUDO - containers, volumes, dados, configuraÃ§Ãµes!

## ï¿½ï¿½ï¸ **Arquitetura**

### **Abordagem HÃ­brida: Docker + Python**
- **Docker**: Apenas para infraestrutura (PostgreSQL, MinIO, DBT Runner)
- **Python**: ExecuÃ§Ã£o de lÃ³gica (DBT, verificaÃ§Ãµes, criaÃ§Ã£o de tabelas)
- **Credenciais Padronizadas**: admin/admin para todos os serviÃ§os

### **Fluxo de Dados**
```
1. PostgreSQL Source (dados originais)
   â†“
2. DBT para transformaÃ§Ãµes de dados
   â†“
3. PostgreSQL Target (dados replicados)
   â†“
4. DBT Python (transformaÃ§Ãµes)
   â†“
5. Dashboard Streamlit
```

## ğŸ“Š **Estrutura de Dados**

### **Tabelas Principais:**
- **clientes** - Dados de clientes com perfil empresarial
- **pedidos** - Pedidos sem itens (estrutura empresarial)
- **produtos** - CatÃ¡logo de produtos e-commerce
- **itens_pedido** - Relacionamento produtosâ†”pedidos
- **campanhas_marketing** - Campanhas de marketing
- **leads** - Leads gerados pelas campanhas

### **Camadas DBT:**
- **ğŸ¥‰ Bronze** - Dados brutos do banco de origem
- **ğŸ¥ˆ Silver** - Dados limpos e padronizados
- **ğŸ¥‡ Gold** - AgregaÃ§Ãµes e mÃ©tricas de negÃ³cio

## ğŸŒ **URLs dos ServiÃ§os**

| ServiÃ§o | URL | Credenciais | DescriÃ§Ã£o |
|---------|-----|-------------|-----------|
| **ğŸ¯ Dashboard Principal** | http://localhost:8501 | - | Interface web principal com mÃ©tricas |
| **ğŸ“š DBT Docs** | http://localhost:8080 | - | DocumentaÃ§Ã£o do DBT (apÃ³s `dbt docs serve`) |
| **ğŸ—„ï¸ MinIO Console** | http://localhost:9001 | minioadmin/minioadmin | Data Lake S3-compatible |
| **ğŸ˜ PostgreSQL Source** | localhost:5430 | admin/admin | Banco de dados transacional |

## ğŸ“Š **Comandos DBT Detalhados**

```bash
# Navegar para o projeto DBT
cd dbt_project

# Instalar dependÃªncias do DBT
dbt deps

# Executar modelos por camada (ordem recomendada)
dbt run --models tag:bronze    # ğŸ¥‰ Camada Bronze
dbt run --models tag:silver    # ğŸ¥ˆ Camada Silver  
dbt run --models tag:gold      # ğŸ¥‡ Camada Gold

# Executar pipeline completo
dbt run

# Inserir dados de referÃªncia (seeds)
dbt seed

# Executar testes de qualidade
dbt test

# Gerar e servir documentaÃ§Ã£o
dbt docs generate
dbt docs serve --port 8080

# ExecuÃ§Ã£o via Python (automatizada)
python ../scripts/executar_dbt.py debug    # Testar conexÃ£o
python ../scripts/executar_dbt.py bronze   # Modelos bronze
python ../scripts/executar_dbt.py silver   # Modelos silver
python ../scripts/executar_dbt.py gold     # Modelos gold
python ../scripts/executar_dbt.py full     # Pipeline completo

# Scheduler automÃ¡tico (execuÃ§Ã£o contÃ­nua)
python ../scripts/scheduler_dbt.py --interval 300  # A cada 5 minutos
python ../scripts/scheduler_dbt.py --run-once      # Apenas uma vez
```

## ğŸ› ï¸ **Comandos Ãšteis**

```bash
# === PIPELINE PRINCIPAL ===
# Iniciar ambiente completo (recomendado)
./start_pipeline.sh

# Iniciar apenas DBT pipeline  
./scripts/start_dbt_pipeline.sh

# Apenas construir serviÃ§os sem executar
./scripts/start_dbt_pipeline.sh --build-only

# Iniciar com logs visÃ­veis
./scripts/start_dbt_pipeline.sh --logs

# Parar todos os serviÃ§os
docker-compose -f config/docker-compose.yml down

# Limpar ambiente completamente
./clean_docker_environment.sh

# === DBT ===
# Executar DBT por camadas
cd dbt_project
dbt run --models tag:bronze    # Camada Bronze
dbt run --models tag:silver    # Camada Silver  
dbt run --models tag:gold      # Camada Gold
dbt run                        # Pipeline completo

# Executar testes
dbt test

# Gerar e servir documentaÃ§Ã£o
dbt docs generate && dbt docs serve

# Executar via container
docker-compose -f config/docker-compose.yml exec dbt_runner dbt run

# === AUTOMAÃ‡ÃƒO ===
# Scheduler automÃ¡tico (a cada 5 minutos)
python scripts/scheduler_dbt.py --interval 300

# Scheduler uma Ãºnica execuÃ§Ã£o
python scripts/scheduler_dbt.py --run-once

# Dashboard independente
streamlit run scripts/dashboard.py

# === DADOS ===
# Inserir dados manualmente
python scripts/insere_dados.py

# Conectar ao banco via psql
psql -h localhost -p 5430 -U admin -d db_source

# === MONITORAMENTO ===
# Status dos containers
docker-compose -f config/docker-compose.yml ps

# Ver logs de todos os serviÃ§os
docker-compose -f config/docker-compose.yml logs -f

# Logs especÃ­ficos
docker-compose -f config/docker-compose.yml logs -f postgres_source
docker-compose -f config/docker-compose.yml logs -f dbt_runner
docker-compose -f config/docker-compose.yml logs -f minio

# Verificar saÃºde dos serviÃ§os
docker-compose -f config/docker-compose.yml exec postgres_source pg_isready -U admin
```

## ğŸ“ **Estrutura do Projeto**

```
â”œâ”€â”€ start_pipeline.sh              # ğŸ¯ Script principal (pipeline completo)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start_dbt_pipeline.sh       # ğŸ”§ Pipeline DBT focado
â”‚   â”œâ”€â”€ scheduler_dbt.py            # ğŸ”„ ExecuÃ§Ã£o automÃ¡tica
â”‚   â”œâ”€â”€ dashboard.py                # ğŸ“Š Interface web Streamlit  
â”‚   â”œâ”€â”€ insere_dados.py             # ğŸ“ InserÃ§Ã£o de dados
â”‚   â””â”€â”€ executar_dbt.py             # ğŸ› ï¸ ExecuÃ§Ã£o manual DBT
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ env.config                  # ğŸ”§ VariÃ¡veis centralizadas
â”‚   â”œâ”€â”€ docker-compose.yml          # ğŸ³ ConfiguraÃ§Ã£o completa
â”‚   â””â”€â”€ load_env.sh                 # ğŸ“‹ Helper para variÃ¡veis
â”œâ”€â”€ postgres_init_scripts/
â”‚   â””â”€â”€ init_source_db.sql          # ğŸ—„ï¸ Schema do banco source
â”œâ”€â”€ dbt_project/                    # ğŸ—ï¸ Projeto DBT
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ bronze/                 # ğŸ¥‰ Camada Bronze (dados brutos)
â”‚   â”‚   â”œâ”€â”€ silver/                 # ğŸ¥ˆ Camada Silver (limpos)
â”‚   â”‚   â””â”€â”€ gold/                   # ğŸ¥‡ Camada Gold (agregaÃ§Ãµes)
â”‚   â”œâ”€â”€ seeds/                      # ğŸŒ± Dados de referÃªncia
â”‚   â”œâ”€â”€ tests/                      # ğŸ§ª Testes de qualidade
â”‚   â””â”€â”€ dbt_project.yml             # âš™ï¸ ConfiguraÃ§Ã£o DBT
â””â”€â”€ dbt_profiles/
    â””â”€â”€ profiles.yml                # ğŸ”Œ ConexÃµes DBT
```

## ğŸš¨ **Troubleshooting**

### **Problema: "role admin does not exist"**
```bash
# SoluÃ§Ã£o: Reset completo do ambiente
cd config && docker compose down --volumes
docker system prune -f
./start_pipeline.sh
```

### **Problema: DBT nÃ£o encontra tabelas**
1. Verifique se os dados estÃ£o no banco:
```bash
docker compose -f config/docker-compose.yml exec postgres_source psql -U admin -d db_source -c "SELECT COUNT(*) FROM clientes;"
```

2. Se retornar erro, execute inserÃ§Ã£o manual:
```bash
python scripts/insere_dados.py
```

### **Problema: Dashboard nÃ£o carrega**
1. Verifique se o Streamlit estÃ¡ instalado:
```bash
pip install streamlit plotly pandas psycopg2-binary
```

2. Execute o dashboard manualmente:
```bash
streamlit run scripts/dashboard.py
```

### **Problema: Portas ocupadas**
```bash
# Verificar portas em uso
lsof -i :5430 -i :8501 -i :9001

# Parar processos conflitantes
docker compose -f config/docker-compose.yml down --remove-orphans
```

### **Problema: Pipeline nÃ£o inicia automaticamente**
1. Verifique dependÃªncias:
```bash
python scripts/verificar_ambiente.py
```

2. Execute etapas manualmente:
```bash
./scripts/start_dbt_pipeline.sh --build-only
python scripts/insere_dados.py
cd dbt_project && dbt run
streamlit run scripts/dashboard.py
```

## ğŸ”„ **Ordem do Pipeline (SequÃªncia Completa)**

### **ExecuÃ§Ã£o AutomÃ¡tica (start_pipeline.sh)**
```
1. ï¿½ Instalar dependÃªncias Python
2. ğŸ³ Iniciar containers (PostgreSQL + MinIO + DBT Runner)  
3. â³ Aguardar serviÃ§os ficarem prontos
4. ğŸ“ Inserir dados iniciais no PostgreSQL
5. ğŸ› ï¸ Executar transformaÃ§Ãµes DBT (Bronze â†’ Silver â†’ Gold)
6. ğŸ“Š Abrir dashboard Streamlit automaticamente
7. ğŸ”„ Iniciar inserÃ§Ã£o contÃ­nua de dados em background
8. âœ… Pipeline pronto para uso
```

### **Camadas DBT (Ordem de ExecuÃ§Ã£o)**
```
ğŸ¥‰ Bronze: CÃ³pia exata dos dados source (clientes, pedidos, produtos)
ğŸ¥ˆ Silver: Limpeza e padronizaÃ§Ã£o (dimensÃµes e fatos)  
ğŸ¥‡ Gold: AgregaÃ§Ãµes e mÃ©tricas de negÃ³cio (anÃ¡lises e KPIs)
```

### **Monitoramento em Tempo Real**
- **Dashboard**: Atualiza automaticamente a cada 5 segundos
- **InserÃ§Ã£o**: Novos dados a cada 30 segundos
- **Scheduler**: Executa DBT conforme configurado

## ğŸ¯ **PrÃ³ximos Passos**

### **Para DemonstraÃ§Ã£o RÃ¡pida:**
1. Execute `./start_pipeline.sh`
2. Aguarde 3-5 minutos para inicializaÃ§Ã£o completa
3. Dashboard abrirÃ¡ automaticamente no navegador
4. Explore as mÃ©tricas atualizando em tempo real

### **Para Desenvolvimento/AnÃ¡lise:**
1. Acesse MinIO Console: http://localhost:9001
2. Conecte ao PostgreSQL: `psql -h localhost -p 5430 -U admin -d db_source`
3. Explore modelos DBT: `cd dbt_project && dbt docs serve`
4. Configure scheduler: `python scripts/scheduler_dbt.py --interval 300`

### **Para CustomizaÃ§Ã£o:**
1. Modifique modelos DBT em `dbt_project/models/`
2. Ajuste dashboard em `scripts/dashboard.py`
3. Configure inserÃ§Ã£o de dados em `scripts/insere_dados.py`
4. Personalize variÃ¡veis em `config/env.config`

---

**ğŸ‰ Pipeline DBT completo pronto para demonstraÃ§Ã£o com credenciais admin/admin!**

## ğŸ“š **DocumentaÃ§Ã£o Complementar**

- ğŸš€ **[Guia de InicializaÃ§Ã£o](README_START_PIPELINE.md)** - Como usar o script automatizado
- ğŸ“Š **[Capacidades DBT](README_DBT.md)** - GovernanÃ§a, testes, snapshots e funcionalidades avanÃ§adas  
- ğŸ”§ **[Ajustes TÃ©cnicos](AJUSTES_DASHBOARD.md)** - ConfiguraÃ§Ãµes e troubleshooting do dashboard
- ğŸ” **[Credenciais](config/README_CREDENCIAIS.md)** - Sistema centralizado de credenciais
- ğŸ—ï¸ **[Arquiteturas](docs/arquiteturas_comparacao.md)** - ComparaÃ§Ã£o de diferentes abordagens

**ğŸ“– Ordem de leitura recomendada:**
1. Este README (visÃ£o geral)
2. README_START_PIPELINE.md (execuÃ§Ã£o prÃ¡tica)  
3. readme-dbt.md (funcionalidades avanÃ§adas)
4. Demais documentos conforme necessidade